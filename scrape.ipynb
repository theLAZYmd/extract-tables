{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool:\n",
    "1. Downloads all the listings within a given time range from an SEC listing of a company\n",
    "2. Saves all the pages as HTML files\n",
    "3. Compiles an Excel spreadsheet, formatted to FTI specifications, summarising the listing.  \n",
    "\n",
    "Use a tool found in the same folder, named `convert.py` to convert the HTML results into PDF files using the wkhtmltopdf.exe utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests) (1.25.10)\n",
      "Requirement already satisfied: xmltodict in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: datetime in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (4.3)\n",
      "Collecting zope.interface\n",
      "  Using cached zope.interface-5.1.0-cp38-cp38-win32.whl (192 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from datetime) (2020.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from zope.interface->datetime) (47.1.0)\n",
      "Installing collected packages: zope.interface\n",
      "Successfully installed zope.interface-5.1.0\n",
      "Requirement already satisfied: asyncio in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: pyquery in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: cssselect>0.7.9 in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pyquery) (1.1.0)\n",
      "Requirement already satisfied: lxml>=2.1 in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pyquery) (4.5.2)\n",
      "Requirement already satisfied: pathlib in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: jdcal in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from openpyxl) (1.4.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from openpyxl) (1.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (1.19.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pandas) (1.19.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\alip\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alip\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# Comment out the following lines if not running this program in Jupyter and use pip install the normal way.\n",
    "! pip install requests\n",
    "! pip install xmltodict\n",
    "! pip install datetime\n",
    "! pip install asyncio\n",
    "! pip install pyquery\n",
    "! pip install pathlib\n",
    "! pip install openpyxl\n",
    "! pip install numpy\n",
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "import asyncio\n",
    "import datetime\n",
    "from pyquery import PyQuery as pq\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.formats.excel\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Set configuration variables\n",
    "\n",
    "First section is customisable entries to choose data from the SEC\n",
    "Second section is output variables to design for the FTI format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: Set configuration\n",
    "\n",
    "companyName = 'JA Solar'           # Short name, only for file naming purposes\n",
    "workbookTitle = ''              # This is populated automatically but you can choose to specify if you so wish\n",
    "cik = '0001385598'              # We can improve this code to fetch cik from name if so needed\n",
    "keepCodes = ['6-K', '20-F']    # Specify which filings to keep. Write custom functions for data to extract in function locate()\n",
    "                                # ex: ['10-K', '1O-Q', '6-K', '20-F']\n",
    "datestart = '2015-01-01'        # If going very far back in time this script needs to be modified since it only gets the 1st 100 entries\n",
    "dateend = ''\n",
    "base = 'https://www.sec.gov'\n",
    "\n",
    "downloadHTMLs = True\n",
    "outFolder = './data/'\n",
    "outHTMLFolder = './htmls/'\n",
    "\n",
    "# Set configuration for output file (xlsx and downloads)\n",
    "start_row = 7\n",
    "start_column = 1\n",
    "fti_colour = '#44556a'\n",
    "pageBreakSize = 3\n",
    "insertLogo = './FTI.jpg'         # Leave as empty string to not insert logo\n",
    "maxrows = None\n",
    "isTest = False                   # Test runs fetch less data\n",
    "\n",
    "# Download selection configuration\n",
    "def locate(filing):\n",
    "    f = ''\n",
    "    if filing['type'] == '6-K':\n",
    "        f = filing.get('EX-99.1', '')\n",
    "    elif filing['type'] == '20-F':\n",
    "        f = filing.get('20-F', '')\n",
    "    elif filing['type'] == '10-K':\n",
    "        f = filing.get('10-K', '')\n",
    "    elif filing['type'] == '10-Q':\n",
    "        f = filing.get('10-Q', '')\n",
    "    else:\n",
    "        f = filing.get(filing['type'], '')        \n",
    "    if 'ix?doc=/' in f:\n",
    "        f = f.replace('ix?doc=/', '')\n",
    "    return f\n",
    "\n",
    "# Don't set this\n",
    "folder = outFolder + companyName + '/'\n",
    "fileFolder = outHTMLFolder + companyName + '/'\n",
    "if isTest:\n",
    "    maxrows = 2\n",
    "elif len(sys.argv) > 1:\n",
    "    if sys.argv[1] == '--test':\n",
    "        maxrows = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Get the data from the SEC website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(type=''):\n",
    "    params = {\n",
    "        'action': 'getcompany',\n",
    "        'start': 0,\n",
    "        'type': type,\n",
    "        'dateb': dateend,\n",
    "        'owner': '',\n",
    "        'search_text': '',\n",
    "        'CIK': cik,\n",
    "        'count': 100,\n",
    "        'output': 'atom'\n",
    "    }\n",
    "    r = requests.get(base + '/cgi-bin/browse-edgar', params)\n",
    "    print('Index page: ', r.url)\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert the resulting XML into a python dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    return xmltodict.parse(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Handle the dict to remove unwanted terms and select only the data needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse(data):\n",
    "    table = []\n",
    "    rows = []\n",
    "    filingPromises = []\n",
    "    downloadPromises = []\n",
    "    \n",
    "    global workbookTitle\n",
    "    workbookTitle = data['feed']['company-info']['conformed-name']\n",
    "    \n",
    "    if 'entry' in data['feed']:\n",
    "        for i, e in enumerate(data['feed']['entry']):\n",
    "            if not filterScraped(e):\n",
    "                continue\n",
    "            if maxrows != None and i > maxrows:\n",
    "                break\n",
    "            row = {\n",
    "                'date': e['content']['filing-date'],\n",
    "                'type': e['category']['@term'],\n",
    "                'index': e['link']['@href']\n",
    "            }\n",
    "            filingPromises.append(links(row['index']))\n",
    "            rows.append(row)\n",
    "    filings = await asyncio.gather(*filingPromises)\n",
    "\n",
    "    for i in range(0, len(rows)):\n",
    "        filing = { **rows[i],  **filings[i] }\n",
    "        rows[i] = filing\n",
    "        downloadPromises.append(downloadFile(filing))\n",
    "    downloads = await asyncio.gather(*downloadPromises)\n",
    "\n",
    "    writingPromises = []\n",
    "\n",
    "    for i in range(0, len(rows)):\n",
    "        filing = rows[i]\n",
    "        if downloads[i]:\n",
    "            if not isStatement(downloads[i], filing):\n",
    "                continue\n",
    "            filing['pages'] = getPages(downloads[i])\n",
    "            if downloadHTMLs:\n",
    "                writingPromises.append(writeFile(downloads[i], rows[i]))\n",
    "        else:\n",
    "            filing['pages'] = 0\n",
    "            if filing['type'] == '6-K':\n",
    "                continue\n",
    "        table.append(filing)\n",
    "        \n",
    "    await asyncio.gather(*writingPromises)\n",
    "    \n",
    "    return table\n",
    "\n",
    "def filterScraped(e):\n",
    "    if e['category']['@term'] not in keepCodes:\n",
    "        return False\n",
    "    if datestart and e['content']['filing-date'] < datestart:\n",
    "        return False\n",
    "    if dateend and e['content']['filing-date'] > dateend:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Link pulling and cacheing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def links(url):\n",
    "    d = pq(url=url)\n",
    "    parent = d('table.tableFile tr')\n",
    "    obj = {}\n",
    "    for row in parent:\n",
    "        p = d(row)\n",
    "        link = p('td:nth-child(3) > a')\n",
    "        href = link.attr('href')\n",
    "        if not href:\n",
    "            continue\n",
    "        if href.startswith('/'):\n",
    "            href = base + href\n",
    "        obj[p('td:nth-child(4)').text()] = href\n",
    "    return obj\n",
    "\n",
    "async def downloadFile(filing):\n",
    "    file = locate(filing)\n",
    "    if not file:\n",
    "        print('Err: no filing listed: ', filing)\n",
    "        return\n",
    "    try:\n",
    "        print('Fetching: ' + file)\n",
    "        r = requests.get(file)\n",
    "    except:\n",
    "        print('Err: malformed URL: ', file)\n",
    "        return\n",
    "    html = r.text\n",
    "    return html\n",
    "\n",
    "def getPages(html):\n",
    "    try:\n",
    "        d = pq(html)\n",
    "    except:\n",
    "        n = html.count('page-break-before') + html.count('page-break-after')\n",
    "        if not n:\n",
    "            n = html.count('<hr')\n",
    "        return n\n",
    "    \n",
    "    breaks = d('[style*=\"page-break-before:always\"], [style*=\"page-break-after:always\"], [style*=\"page-break-before: always\"], [style*=\"page-break-after: always\"]')\n",
    "    if not len(breaks):\n",
    "        breaks = d('hr[size=\"' + str(pageBreakSize) + '\"], hr[noshade]')\n",
    "    return len(breaks)\n",
    "\n",
    "def isStatement(html, filing):\n",
    "    if filing['type'] != '6-K':\n",
    "        return True\n",
    "    try:\n",
    "        d = pq(html)\n",
    "    except:\n",
    "        text = html.lower()\n",
    "        if re.search(r\"<b>.*reports.*quarter.*</b>\", text):\n",
    "            return True\n",
    "        return False\n",
    "    bolds = [i.text().lower() for i in d.items('b')]\n",
    "    canReturn = [False, False]\n",
    "    for i, text in enumerate(bolds):\n",
    "        if i > 7:\n",
    "            break\n",
    "        if 'quarter' in text:\n",
    "            canReturn[0] = True\n",
    "        if 'results' in text:\n",
    "            canReturn[1] = True\n",
    "        if canReturn[0] and canReturn[1]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "async def writeFile(html, filing):    \n",
    "    name = ' - '.join([companyName, filing['date'], filing['type']])\n",
    "    f = open(fileFolder + '' + name + '.html', 'w', encoding='utf-8')\n",
    "    f.write(html)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get fieldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFields(arr):\n",
    "    # Note that set().union(*(d.keys() for d in arr)) does the same but doesn't preserve order, which we want\n",
    "    f = ['date', 'type', 'pages', 'index']\n",
    "    for obj in arr:\n",
    "        for k in obj.keys():\n",
    "            if k not in f:\n",
    "                f.append(k)\n",
    "    return f\n",
    "\n",
    "def capitalize(str):\n",
    "    # Format empty strings as Other here too, why not\n",
    "    if not str:\n",
    "        return 'Other'\n",
    "    return str[0].capitalize() + str[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Run and write\n",
    "\n",
    "The main output function called below in main()\n",
    "Writes to an .xlsx file in the same directory with variable name specified above.\n",
    "Formats it in the FTI style automatically. Variables abstracted out above for more personal control.\n",
    "This function's a bit long and messy because of the nature of xlsxwriter maintains the need to keep things in global scope. Read the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(arr):\n",
    "    f = pd.ExcelWriter(companyName + ' - SEC' + '.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    for code in keepCodes:\n",
    "        kept = list(filter(lambda x: x['type'] == code, arr))\n",
    "        columns = getFields(kept)\n",
    "        df = pd.DataFrame(kept, columns=columns)\n",
    "        df.to_excel(\n",
    "            f,\n",
    "            sheet_name=code,\n",
    "            startcol=start_column,\n",
    "            startrow=start_row,\n",
    "            index=False\n",
    "        )\n",
    "        workbook = f.book\n",
    "        worksheet = f.sheets[code]\n",
    "\n",
    "        # Header formats\n",
    "        header_format = workbook.add_format({\n",
    "            'bold': True,\n",
    "            'bg_color': 'white',\n",
    "            'border': 0,\n",
    "            'align': 'left'\n",
    "        })\n",
    "        header_format.set_bottom(1)\n",
    "        header_format.set_top(1)\n",
    "        for col_num, value in enumerate(df.columns.values):\n",
    "               worksheet.write(start_row, col_num + 1, capitalize(value), header_format)\n",
    "\n",
    "        # Footer formats\n",
    "        footer_format = workbook.add_format({\n",
    "            'bg_color': 'white',\n",
    "            'border': 0,\n",
    "        })\n",
    "        footer_format.set_top(2)\n",
    "        for col_num in range(0, len(df.columns.values)):\n",
    "            worksheet.write(start_row + 1 + len(df), col_num + 1, '', footer_format)\n",
    "\n",
    "        # Default formats for any FTI sheet\n",
    "        std_fmt = workbook.add_format({ 'border': 0, 'bg_color': 'white' })\n",
    "        bold_fmt = workbook.add_format({ 'bold': True, 'border': 0, 'bg_color': 'white' })\n",
    "        highlighted_fmt = workbook.add_format({ 'bold': True, 'border': 0, 'color': 'white', 'bg_color': fti_colour })\n",
    "\n",
    "        worksheet.set_column('C:Z', None, std_fmt)\n",
    "        worksheet.set_column(0, start_column - 1, 2, std_fmt)\n",
    "        worksheet.set_column('B:B', 12, std_fmt)\n",
    "        worksheet.write('B2', companyName + ' - ' + cik, bold_fmt)\n",
    "        worksheet.write('B3', workbookTitle, bold_fmt)\n",
    "        worksheet.write('B4', 'FTI Consulting', bold_fmt)\n",
    "        \n",
    "        if insertLogo:\n",
    "            worksheet.insert_image('D2', insertLogo)\n",
    "\n",
    "        starty = datestart.split('-')[0]\n",
    "        endy = dateend.split('-')[0] or str(datetime.date.today().year)\n",
    "        worksheet.write(start_row - 2, 1, code + ' (' + starty + '-' + endy + ')', highlighted_fmt)\n",
    "        for col_num in range(1, len(df.columns.values)):\n",
    "            worksheet.write(start_row - 2, col_num + 1, '', highlighted_fmt)\n",
    "            \n",
    "    workbook.close()\n",
    "    print('Wrote to: ', os.getcwd() + '\\\\' + companyName + ' - SEC.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download process...\n",
      "Index page:  https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&start=0&type=6-K&dateb=&owner=&search_text=&CIK=0001385598&count=100&output=atom\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465918045285/a17-28141_8ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465918044489/a18-17063_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465918028048/a18-12372_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465918020759/a18-9226_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465918020311/a18-9140_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465918016562/a18-8069_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465918005754/a18-5176_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465918005706/a17-28141_6ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917069517/a17-27311_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917068799/a17-27168_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917066186/a17-26045_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917053192/a17-20844_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917050536/a17-19941_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917044887/a17-17918_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917043312/a17-16886_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917037764/a17-14821_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917035635/a17-14290_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917034754/a17-14135_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917031765/a17-12954_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917026693/a17-12006_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917017182/a17-8438_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917013747/a17-7573_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917011475/a17-7155_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916157887/a16-21847_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916153988/a16-20956_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916147335/a16-19220_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916140576/a16-16983_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916128171/a16-13560_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916124156/a16-12502_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916120186/a16-10991_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916117328/a16-10445_1ex99d1.htm\n",
      "Err: no filing listed:  {'date': '2016-04-19', 'type': '6-K', 'index': 'https://www.sec.gov/Archives/edgar/data/1385598/000110465916112496/0001104659-16-112496-index.htm', '6-K': 'https://www.sec.gov/Archives/edgar/data/1385598/000110465916112496/a16-8677_16k.htm', '': 'https://www.sec.gov/Archives/edgar/data/1385598/000110465916112496/0001104659-16-112496.txt'}\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916105628/a16-6486_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916100215/a16-5383_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915080053/a15-23666_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915070496/a15-21051_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915058825/a15-17451_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915055530/a15-16710_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915054947/a15-16611_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915045787/a15-14185_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915043809/a15-13638_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915043004/a15-13434_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915039186/a15-12195_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915035993/a15-10949_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915025657/a15-8612_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915019396/a15-6696_1ex99d1.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915015940/a15-5568_1ex99d1.htm\n",
      "Index page:  https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&start=0&type=20-F&dateb=&owner=&search_text=&CIK=0001385598&count=100&output=atom\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465918028057/a18-12009_120f.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465917026369/a16-23343_120f.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465916115305/a16-1510_120f.htm\n",
      "Fetching: https://www.sec.gov/Archives/edgar/data/1385598/000110465915030422/a15-2647_120f.htm\n",
      "Wrote to:  C:\\Users\\alip\\Documents\\JASOL - SEC scraper\\JA Solar - SEC.xlsx\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    print('Starting download process...')\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "    Path(fileFolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    arr = []\n",
    "    for k in keepCodes:\n",
    "        xml = get(k)\n",
    "        obj = convert(xml)\n",
    "        a = await parse(obj)\n",
    "        arr.extend(a)\n",
    "        \n",
    "    fieldnames = getFields(arr)\n",
    "    y = json.dumps(arr, indent=4)\n",
    "\n",
    "    # Creates an intermediate XML output. Mainly for debugging purposes. Comment out if undesirable.\n",
    "    f = open(folder + companyName + '.xml', 'w')\n",
    "    f.write(xml)\n",
    "    f.close()\n",
    "\n",
    "    # Creates an intermediate JSON output. Mainly for debugging purposes. Comment out if undesirable.\n",
    "    f = open(folder + companyName + '.json', 'w')\n",
    "    f.write(y)\n",
    "    f.close()\n",
    "\n",
    "    # Creates an intermediate CSV output. Alternative to pandas.\n",
    "    f = open(folder + companyName + '.csv', 'w', newline='')\n",
    "    r = csv.DictWriter(\n",
    "        f,\n",
    "        delimiter=',',\n",
    "        quotechar='\"',\n",
    "        fieldnames=fieldnames\n",
    "    )\n",
    "    r.writeheader()\n",
    "    r.writerows(arr)\n",
    "    f.close()\n",
    "\n",
    "    # Creates main .xlsx output using pandas.\n",
    "    write(arr)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aloysius Lip 2020\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
